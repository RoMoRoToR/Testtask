{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-20T21:32:20.060943Z",
     "start_time": "2025-06-20T21:32:18.246016Z"
    }
   },
   "source": "!pip install labelImg",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: labelImg in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (1.8.6)\n",
      "Requirement already satisfied: pyqt5 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from labelImg) (5.15.11)\n",
      "Requirement already satisfied: lxml in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from labelImg) (5.4.0)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from pyqt5->labelImg) (12.17.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from pyqt5->labelImg) (5.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:16:14.533776Z",
     "start_time": "2025-06-21T00:10:30.962047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2, os\n",
    "\n",
    "video_dir  = 'video'\n",
    "output_dir = 'frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# кадров в секунду\n",
    "frames_per_sec = 1\n",
    "\n",
    "for vid in os.listdir(video_dir):\n",
    "    if not vid.lower().endswith('.mov'):\n",
    "        continue\n",
    "    path_in  = os.path.join(video_dir, vid)\n",
    "    cap      = cv2.VideoCapture(path_in)\n",
    "    fps      = cap.get(cv2.CAP_PROP_FPS) or frames_per_sec\n",
    "    step     = int(fps / frames_per_sec)\n",
    "    frame_id = 0\n",
    "    sec_id   = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_id % step == 0:\n",
    "            name = f\"{os.path.splitext(vid)[0]}_sec{sec_id:03d}.jpg\"\n",
    "            cv2.imwrite(os.path.join(output_dir, name), frame)\n",
    "            sec_id += 1\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "print(\"Готово — кадры в папке\", output_dir)\n"
   ],
   "id": "e1e976f0da9ea2ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово — кадры в папке frames\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T12:29:49.333738Z",
     "start_time": "2025-06-21T12:29:47.637854Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install labelImg",
   "id": "5d4b07e1b184c84f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: labelImg in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (1.8.6)\n",
      "Requirement already satisfied: pyqt5 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from labelImg) (5.15.11)\n",
      "Requirement already satisfied: lxml in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from labelImg) (5.4.0)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from pyqt5->labelImg) (12.17.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from pyqt5->labelImg) (5.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T20:33:18.030751Z",
     "start_time": "2025-06-21T20:33:17.814916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from shutil import copy2\n",
    "\n",
    "# Параметры разбивки\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO   = 0.15\n",
    "TEST_RATIO  = 0.15\n",
    "SEED        = 42\n",
    "\n",
    "# Пути к исходным данным\n",
    "IMG_DIR   = 'frames'\n",
    "LBL_DIR   = 'labels'\n",
    "\n",
    "# Целевая структура\n",
    "BASE_OUT  = 'dataset'\n",
    "OUT_IMG   = os.path.join(BASE_OUT, 'images')\n",
    "OUT_LBL   = os.path.join(BASE_OUT, 'labels')\n",
    "SPLITS    = ['train', 'val', 'test']\n",
    "\n",
    "# Создаём папки\n",
    "for split in SPLITS:\n",
    "    os.makedirs(os.path.join(OUT_IMG, split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUT_LBL, split), exist_ok=True)\n",
    "\n",
    "# Собираем все изображения\n",
    "all_imgs = glob.glob(os.path.join(IMG_DIR, '*.jpg'))\n",
    "all_imgs.sort()\n",
    "random.seed(SEED)\n",
    "random.shuffle(all_imgs)\n",
    "\n",
    "n = len(all_imgs)\n",
    "n_train = int(n * TRAIN_RATIO)\n",
    "n_val   = int(n * VAL_RATIO)\n",
    "\n",
    "# Определяем диапазоны\n",
    "ranges = {\n",
    "    'train': all_imgs[:n_train],\n",
    "    'val':   all_imgs[n_train:n_train + n_val],\n",
    "    'test':  all_imgs[n_train + n_val:]\n",
    "}\n",
    "\n",
    "# Копируем файлы\n",
    "for split, img_list in ranges.items():\n",
    "    for img_path in img_list:\n",
    "        fn = os.path.basename(img_path)\n",
    "        name, _ = os.path.splitext(fn)\n",
    "        lbl_path = os.path.join(LBL_DIR, f'{name}.txt')\n",
    "        copy2(img_path, os.path.join(OUT_IMG, split, fn))\n",
    "        if os.path.exists(lbl_path):\n",
    "            copy2(lbl_path, os.path.join(OUT_LBL, split, f'{name}.txt'))\n",
    "        else:\n",
    "            print(f'Внимание: нет аннотации для {fn}')\n"
   ],
   "id": "4868c8cf1bdb84ab",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T20:43:47.521654Z",
     "start_time": "2025-06-21T20:43:09.652556Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install albumentations opencv-python\n",
   "id": "7052765e409bd961",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from albumentations) (2.3.0)\n",
      "Collecting scipy>=1.10.0 (from albumentations)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from albumentations) (6.0.2)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-3.12.5-cp312-cp312-win_amd64.whl.metadata (81 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.4.9-cp312-cp312-win_amd64.whl.metadata (67 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\user\\pycharmprojects\\test_task\\.venv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.14.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.1/39.4 MB 15.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 6.0/39.4 MB 14.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 8.4/39.4 MB 13.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 10.7/39.4 MB 12.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 12.8/39.4 MB 12.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.7/39.4 MB 12.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 16.8/39.4 MB 11.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 18.9/39.4 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/39.4 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/39.4 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.6/39.4 MB 10.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.5/39.4 MB 10.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.6/39.4 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.7/39.4 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.8/39.4 MB 10.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.4/39.4 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/39.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 1.8/2.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading scipy-1.15.3-cp312-cp312-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/41.0 MB 9.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.9/41.0 MB 9.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.0/41.0 MB 10.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.9/41.0 MB 9.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.0/41.0 MB 9.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.8/41.0 MB 9.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.9/41.0 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.0/41.0 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 18.4/41.0 MB 9.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.7/41.0 MB 9.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 23.1/41.0 MB 10.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.0/41.0 MB 10.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.8/41.0 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/41.0 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.6/41.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.7/41.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading simsimd-6.4.9-cp312-cp312-win_amd64.whl (95 kB)\n",
      "Downloading stringzilla-3.12.5-cp312-cp312-win_amd64.whl (80 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: stringzilla, simsimd, typing-inspection, scipy, pydantic-core, opencv-python-headless, annotated-types, pydantic, albucore, albumentations\n",
      "\n",
      "   ---- -----------------------------------  1/10 [simsimd]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   ------------ ---------------------------  3/10 [scipy]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   -------------------- -------------------  5/10 [opencv-python-headless]\n",
      "   ------------------------ ---------------  6/10 [annotated-types]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ---------------------------- -----------  7/10 [pydantic]\n",
      "   ------------------------------------ ---  9/10 [albumentations]\n",
      "   ------------------------------------ ---  9/10 [albumentations]\n",
      "   ------------------------------------ ---  9/10 [albumentations]\n",
      "   ------------------------------------ ---  9/10 [albumentations]\n",
      "   ------------------------------------ ---  9/10 [albumentations]\n",
      "   ------------------------------------ ---  9/10 [albumentations]\n",
      "   ---------------------------------------- 10/10 [albumentations]\n",
      "\n",
      "Successfully installed albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 opencv-python-headless-4.11.0.86 pydantic-2.11.7 pydantic-core-2.33.2 scipy-1.15.3 simsimd-6.4.9 stringzilla-3.12.5 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T21:12:18.138387Z",
     "start_time": "2025-06-21T21:11:46.555072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import yaml\n",
    "import random\n",
    "from albumentations import (\n",
    "    Compose, RandomRotate90, HorizontalFlip,\n",
    "    RandomBrightnessContrast, HueSaturationValue,\n",
    "    ShiftScaleRotate, GaussianBlur, BboxParams\n",
    ")\n",
    "\n",
    "# Параметры\n",
    "SRC_IMG_DIR   = 'dataset/images/train'\n",
    "SRC_LBL_DIR   = 'dataset/labels/train'\n",
    "OUT_IMG_DIR   = 'augmented/images/train'\n",
    "OUT_LBL_DIR   = 'augmented/labels/train'\n",
    "N_AUG_PER_IMG = 3     #  аугментаций на каждый кадр\n",
    "SEED          = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "os.makedirs(OUT_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_LBL_DIR, exist_ok=True)\n",
    "\n",
    "transform = Compose([\n",
    "    RandomRotate90(p=0.5),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "    GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "],\n",
    "bbox_params=BboxParams(\n",
    "    format='yolo',\n",
    "    label_fields=['class_labels'],\n",
    "    min_visibility=0.3\n",
    "))\n",
    "\n",
    "def read_yolo_annotation(path):\n",
    "    bboxes, labels = [], []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            cls_id = int(parts[0])\n",
    "            x_center, y_center, w, h = map(float, parts[1:])\n",
    "            bboxes.append([x_center, y_center, w, h])\n",
    "            labels.append(cls_id)\n",
    "    return bboxes, labels\n",
    "\n",
    "def save_yolo_annotation(path, bboxes, labels):\n",
    "    with open(path, 'w') as f:\n",
    "        for bbox, cls_id in zip(bboxes, labels):\n",
    "            x_center, y_center, w, h = bbox\n",
    "            f.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "all_imgs = glob.glob(os.path.join(SRC_IMG_DIR, '*.jpg'))\n",
    "for img_path in all_imgs:\n",
    "    name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    lbl_path = os.path.join(SRC_LBL_DIR, name + '.txt')\n",
    "    if not os.path.exists(lbl_path):\n",
    "        print(f\"Пропускаем {name}, нет .txt\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    h, w = image.shape[:2]\n",
    "    bboxes, class_labels = read_yolo_annotation(lbl_path)\n",
    "\n",
    "    # Для каждой аугментации\n",
    "    for i in range(N_AUG_PER_IMG):\n",
    "        augmented = transform(\n",
    "            image=image,\n",
    "            bboxes=bboxes,\n",
    "            class_labels=class_labels\n",
    "        )\n",
    "        img_aug = augmented['image']\n",
    "        bboxes_aug = augmented['bboxes']\n",
    "        labels_aug = augmented['class_labels']\n",
    "\n",
    "        if len(bboxes_aug) == 0:\n",
    "            continue\n",
    "\n",
    "        out_name = f\"{name}_aug{i:02d}.jpg\"\n",
    "        out_img_path = os.path.join(OUT_IMG_DIR, out_name)\n",
    "        out_lbl_path = os.path.join(OUT_LBL_DIR, f\"{name}_aug{i:02d}.txt\")\n",
    "\n",
    "        cv2.imwrite(out_img_path, img_aug)\n",
    "        save_yolo_annotation(out_lbl_path, bboxes_aug, labels_aug)\n",
    "\n",
    "print(\"Аугментация завершена.\")\n"
   ],
   "id": "6645d98f5e8564f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\PycharmProjects\\test_task\\.venv\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аугментация завершена.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T21:53:38.702222Z",
     "start_time": "2025-06-21T21:53:38.670597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "orig_img_dir = 'dataset/images/train'\n",
    "orig_lbl_dir = 'dataset/labels/train'\n",
    "aug_img_dir  = 'augmented/images/train'\n",
    "aug_lbl_dir  = 'augmented/labels/train'\n",
    "\n",
    "merged_base   = 'merged'\n",
    "merged_img_dir = os.path.join(merged_base, 'images', 'train')\n",
    "merged_lbl_dir = os.path.join(merged_base, 'labels', 'train')\n",
    "\n",
    "os.makedirs(merged_img_dir, exist_ok=True)\n",
    "os.makedirs(merged_lbl_dir, exist_ok=True)\n",
    "\n",
    "def copy_all(src_pattern, dst_dir):\n",
    "    for src_path in glob.glob(src_pattern):\n",
    "        fn = os.path.basename(src_path)\n",
    "        dst_path = os.path.join(dst_dir, fn)\n",
    "        if os.path.exists(dst_path):\n",
    "            continue\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "copy_all(os.path.join(orig_img_dir, '*.jpg'), merged_img_dir)\n",
    "copy_all(os.path.join(orig_lbl_dir, '*.txt'), merged_lbl_dir)\n",
    "\n",
    "copy_all(os.path.join(aug_img_dir, '*.jpg'), merged_img_dir)\n",
    "copy_all(os.path.join(aug_lbl_dir, '*.txt'), merged_lbl_dir)\n",
    "\n",
    "print(f\"Готово! В папке `{merged_base}` теперь {len(os.listdir(merged_img_dir))} изображений и \"\n",
    "      f\"{len(os.listdir(merged_lbl_dir))} аннотаций.\")\n"
   ],
   "id": "c492555ec65a916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово! В папке `merged` теперь 280 изображений и 280 аннотаций.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:08:14.076052Z",
     "start_time": "2025-06-22T14:08:10.276251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Загружаем модель (с нуля или из предобученных весов)\n",
    "#  - ''  → обучение с нуля\n",
    "#  - 'yolo11s.pt' → дообучение от предобученной small-модели\n",
    "model = YOLO('', task='detect', cfg='yolov11s.yaml')\n"
   ],
   "id": "e088a5ce192b0228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\User\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "YOLO.__init__() got an unexpected keyword argument 'cfg'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01multralytics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m YOLO\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# 1. Загружаем модель (с нуля или из предобученных весов)\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m#  - ''  → обучение с нуля\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m#  - 'yolo11s.pt' → дообучение от предобученной small-модели\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m model = \u001B[43mYOLO\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdetect\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43myolov11s.yaml\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: YOLO.__init__() got an unexpected keyword argument 'cfg'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2. Запускаем обучение\n",
    "results = model.train(\n",
    "    data='../data.yaml',   # путь к data.yaml\n",
    "    epochs=100,            # количество эпох\n",
    "    imgsz=640,             # размер входа\n",
    "    batch=16,              # batch size\n",
    "    device=0,              # GPU0, можно 'cpu'\n",
    "    name='my_experiment',  # имя экспириента\n",
    "    lr0=0.01,              # начальный learning rate\n",
    "    optimizer='SGD',       # оптимизатор\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    save=True              # сохранять чекпоинты\n",
    ")\n",
    "\n",
    "# 3. После тренировки — валидация (опционально)\n",
    "metrics = model.val(\n",
    "    data='../data.yaml',\n",
    "    weights=results.best,  # лучший чекпоинт\n",
    "    imgsz=640,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "print(metrics)\n"
   ],
   "id": "fb2ed53d00d002ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T16:21:56.070433Z",
     "start_time": "2025-06-22T16:21:56.062719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch, torchvision, torchaudio\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"TorchVision:\", torchvision.__version__)\n",
    "print(\"Torchaudio:\", torchaudio.__version__)\n"
   ],
   "id": "bc6773e5e573e3fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.7.1+cpu\n",
      "CUDA available: False\n",
      "CUDA version: None\n",
      "TorchVision: 0.22.1+cu118\n",
      "Torchaudio: 2.7.1+cu118\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T15:41:13.936894Z",
     "start_time": "2025-06-22T15:41:13.499916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Загружаем модель\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "# Обучаем\n",
    "results = model.train(\n",
    "    data=\"data.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=1,\n",
    "    project=\"runs/train\",\n",
    "    name=\"food_exp_py\"\n",
    ")\n",
    "\n",
    "# Сохраняем лучший чекпоинт вручную (если нужно)\n",
    "print(\"Лучшие веса:\", results.best)\n"
   ],
   "id": "d9b49dfca4c40b9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.158  Python-3.12.1 torch-2.7.1+cpu \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=1' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m model = YOLO(\u001B[33m\"\u001B[39m\u001B[33myolo11s.pt\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# Обучаем\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m results = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdata.yaml\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m640\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproject\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mruns/train\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfood_exp_py\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     15\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# Сохраняем лучший чекпоинт вручную (если нужно)\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mЛучшие веса:\u001B[39m\u001B[33m\"\u001B[39m, results.best)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\test_task\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:791\u001B[39m, in \u001B[36mModel.train\u001B[39m\u001B[34m(self, trainer, **kwargs)\u001B[39m\n\u001B[32m    788\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m args.get(\u001B[33m\"\u001B[39m\u001B[33mresume\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    789\u001B[39m     args[\u001B[33m\"\u001B[39m\u001B[33mresume\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mself\u001B[39m.ckpt_path\n\u001B[32m--> \u001B[39m\u001B[32m791\u001B[39m \u001B[38;5;28mself\u001B[39m.trainer = \u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_smart_load\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtrainer\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43moverrides\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_callbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    792\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args.get(\u001B[33m\"\u001B[39m\u001B[33mresume\u001B[39m\u001B[33m\"\u001B[39m):  \u001B[38;5;66;03m# manually set model only if not resuming\u001B[39;00m\n\u001B[32m    793\u001B[39m     \u001B[38;5;28mself\u001B[39m.trainer.model = \u001B[38;5;28mself\u001B[39m.trainer.get_model(weights=\u001B[38;5;28mself\u001B[39m.model \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ckpt \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, cfg=\u001B[38;5;28mself\u001B[39m.model.yaml)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\test_task\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:121\u001B[39m, in \u001B[36mBaseTrainer.__init__\u001B[39m\u001B[34m(self, cfg, overrides, _callbacks)\u001B[39m\n\u001B[32m    119\u001B[39m \u001B[38;5;28mself\u001B[39m.args = get_cfg(cfg, overrides)\n\u001B[32m    120\u001B[39m \u001B[38;5;28mself\u001B[39m.check_resume(overrides)\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m \u001B[38;5;28mself\u001B[39m.device = \u001B[43mselect_device\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[38;5;66;03m# Update \"-1\" devices so post-training val does not repeat search\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28mself\u001B[39m.args.device = os.getenv(\u001B[33m\"\u001B[39m\u001B[33mCUDA_VISIBLE_DEVICES\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m.device) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m.device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\test_task\\.venv\\Lib\\site-packages\\ultralytics\\utils\\torch_utils.py:201\u001B[39m, in \u001B[36mselect_device\u001B[39m\u001B[34m(device, batch, newline, verbose)\u001B[39m\n\u001B[32m    194\u001B[39m         LOGGER.info(s)\n\u001B[32m    195\u001B[39m         install = (\n\u001B[32m    196\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    197\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mCUDA devices are seen by torch.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    198\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.device_count() == \u001B[32m0\u001B[39m\n\u001B[32m    199\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    200\u001B[39m         )\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    202\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInvalid CUDA \u001B[39m\u001B[33m'\u001B[39m\u001B[33mdevice=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m requested.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    203\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m Use \u001B[39m\u001B[33m'\u001B[39m\u001B[33mdevice=cpu\u001B[39m\u001B[33m'\u001B[39m\u001B[33m or pass valid CUDA device(s) if available,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    204\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m i.e. \u001B[39m\u001B[33m'\u001B[39m\u001B[33mdevice=0\u001B[39m\u001B[33m'\u001B[39m\u001B[33m or \u001B[39m\u001B[33m'\u001B[39m\u001B[33mdevice=0,1,2,3\u001B[39m\u001B[33m'\u001B[39m\u001B[33m for Multi-GPU.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    205\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mtorch.cuda.is_available(): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch.cuda.is_available()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    206\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mtorch.cuda.device_count(): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch.cuda.device_count()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    207\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mos.environ[\u001B[39m\u001B[33m'\u001B[39m\u001B[33mCUDA_VISIBLE_DEVICES\u001B[39m\u001B[33m'\u001B[39m\u001B[33m]: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvisible\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    208\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minstall\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    209\u001B[39m         )\n\u001B[32m    211\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m cpu \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mps \u001B[38;5;129;01mand\u001B[39;00m torch.cuda.is_available():  \u001B[38;5;66;03m# prefer GPU if available\u001B[39;00m\n\u001B[32m    212\u001B[39m     devices = device.split(\u001B[33m\"\u001B[39m\u001B[33m,\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m0\u001B[39m\u001B[33m\"\u001B[39m  \u001B[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: Invalid CUDA 'device=1' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
